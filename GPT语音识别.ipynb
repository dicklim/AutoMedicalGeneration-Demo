{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d3c5de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import base64\n",
    "import pyaudio\n",
    "from pyaudio import PyAudio, paInt16\n",
    "import webbrowser\n",
    "from aip import AipSpeech # 导入api接口\n",
    "from playsound import playsound\t# 音频模块\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4fc2227",
   "metadata": {},
   "outputs": [],
   "source": [
    "framerate = 16000  # Sampling rate\n",
    "num_samples = 2000  # Sampling checkpoints\n",
    "channels = 1  # Sound channels\n",
    "sampwidth = 2  # Sampling width in bytes (2 bytes)\n",
    "FILEPATH = 'speech.wav'\n",
    "\n",
    "base_url = \"https://openapi.baidu.com/oauth/2.0/token?grant_type=client_credentials&client_id=%s&client_secret=%s\"\n",
    "APIKey = '1'  # Your own API Key, see https://ai.baidu.com/tech/speech for more detail\n",
    "SecretKey = '' # Your own SecretKey, see https://ai.baidu.com/tech/speech for more detail\n",
    "\n",
    "HOST = base_url % (APIKey, SecretKey)\n",
    "\n",
    "client = AipSpeech('101110829', APIKey, SecretKey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adc720f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_sound(data):\n",
    "    '''\n",
    "    'per': 4  choose speaker，0: women, 1: man, 3：Emotional synthesis-Du Xiaoyao, 4: Emotional synthesis--Du Yaya\n",
    "    '''\n",
    "    result = client.synthesis(data, 'zh', 1, {\n",
    "        'per': 3,\n",
    "        'spd': 4,    # speed of speaking\n",
    "        'vol': 6,   # volumn\n",
    "        'pit':5\n",
    "    })\n",
    "\n",
    "    if not isinstance(result, dict):\n",
    "        with open('D:/Code/JupyterNotebook/test.mp3', 'wb') as f:\n",
    "            f.write(result)\n",
    "        \n",
    "        f.close()\n",
    "    # play\n",
    "    playsound(\"D:/Code/JupyterNotebook/test.mp3\")\n",
    "    \n",
    "\n",
    "\n",
    "def getToken(host):\n",
    "    res = requests.post(host)\n",
    "    return res.json()['access_token']\n",
    "\n",
    "\n",
    "def save_wave_file(filepath, data):\n",
    "    wf = wave.open(filepath, 'wb')\n",
    "    wf.setnchannels(channels)\n",
    "    wf.setsampwidth(sampwidth)\n",
    "    wf.setframerate(framerate)\n",
    "    wf.writeframes(b''.join(data))\n",
    "    wf.close()\n",
    "\n",
    "        \n",
    "# 在上述代码中，我们通过`callback`函数来处理每次读取的音频帧。在`callback`函数中，\n",
    "# 我们计算了音频帧的音量，并与阈值进行比较。当音量低于阈值时，我们停止录音，关闭音频流，并终止pyaudio。\n",
    "# 你可以根据自己的需求调整阈值和其他参数，以适应不同的录音场景。\n",
    "# 另外，以下是一些可能的阈值设置示例：\n",
    "# 1. 静音录音：如果你只想录制有声音的部分，可以将阈值设置为一个较高的值，如2000。\n",
    "# 2. 语音识别：如果你想录制语音用于语音识别，可以将阈值设置为一个适中的值，如1000。\n",
    "# 3. 噪音检测：如果你想检测环境中的噪音水平，可以将阈值设置为一个较低的值，如500。\n",
    "# 根据具体的应用场景和需求，你可以根据实际情况调整阈值和其他参数。\n",
    "\n",
    "# In the above code, we use the ` callback ` function to process each audio frame read.\n",
    "# In the 'callback' function, we calculated the volume of the audio frames and compared it with a threshold.\n",
    "# When the volume is below the threshold, we stop recording, close the audio stream, and terminate pyaudio.\n",
    "# You can adjust the threshold and other parameters according to your own needs to adapt to different recording scenarios.\n",
    "# Additionally, the following are some possible examples of threshold settings:\n",
    "# 1. Silent recording: If you only want to record the part with sound, you can set the threshold to a higher value, such as 2000.\n",
    "# 2. Speech recognition: If you want to record speech for speech recognition, you can set the threshold to a moderate value, such as 1000.\n",
    "# 3. Noise detection: If you want to detect the level of noise in the environment, you can set the threshold to a lower value, such as 500.\n",
    "#According to specific application scenarios and requirements, you can adjust the threshold and other parameters based on the actual situation.\n",
    "\n",
    "\n",
    "def my_record():\n",
    "    CHUNK = 1024  # Size of each audio frame read\n",
    "    FORMAT = paInt16  # Audio format\n",
    "    CHANNELS = 1  # Number of channels\n",
    "    RATE = 16000  # Sampling rate\n",
    "    THRESHOLD = 1000  # Volume threshold\n",
    "    delayTime=1.3  # Automatically stop after 1.3 seconds of low volume    \n",
    "    \n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "    # snowboydecoder.play_audio_file()\n",
    "#     print(\"Start\")\n",
    "\n",
    "    frames = []\n",
    "    flag = False      # Start recording node\n",
    "    stat = True       # Determine whether to continue recording\n",
    "    stat2 = False     # Determine if the sound is low\n",
    "\n",
    "    tempnum = 0   #tempnum、tempnum2、tempnum3为时间\n",
    "    tempnum2 = 0\n",
    "\n",
    "    while stat:\n",
    "        data = stream.read(CHUNK,exception_on_overflow = False)\n",
    "        frames.append(data)\n",
    "        audio_data = np.frombuffer(data, dtype=np.short)\n",
    "        temp = np.max(audio_data)\n",
    "        if temp > THRESHOLD and flag==False:\n",
    "            flag =True\n",
    "#             print(\"Start record\")\n",
    "            tempnum2=tempnum\n",
    "        if flag:\n",
    "\n",
    "            if(temp < THRESHOLD and stat2==False):\n",
    "                stat2 = True\n",
    "                tempnum2 = tempnum\n",
    "#                 print(\"low volumn, recording the current point.\")\n",
    "            if(temp > THRESHOLD):\n",
    "                stat2 =False\n",
    "                tempnum2 = tempnum\n",
    "                # 刷新\n",
    "            if(tempnum > tempnum2 + delayTime*15 and stat2==True):\n",
    "#                 print(\"Start checking if it's still quiet after an interval of %.2lfs.\" % delayTime)\n",
    "                if(stat2 and temp < THRESHOLD):\n",
    "                    stat = False\n",
    "                    #还是小声，则stat=True\n",
    "#                     print(\"Low volumn\")\n",
    "                else:\n",
    "                    stat2 = False\n",
    "#                     print(\"Large volumn\")\n",
    "\n",
    "\n",
    "#         print(str(temp)  +  \"      \" +  str(tempnum))\n",
    "        tempnum = tempnum + 1\n",
    "        if tempnum > 150:  # Exit directly upon timeout\n",
    "            stat = False\n",
    "#     print(\"Stop record\")\n",
    "    p.terminate()\n",
    "#     print(data)\n",
    "    save_wave_file(FILEPATH, frames)\n",
    "    stream.close()\n",
    "\n",
    "\n",
    "def get_audio(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        data = f.read()\n",
    "    return data\n",
    "\n",
    "\n",
    "def speech2text(speech_data, token, dev_pid=1537):\n",
    "    FORMAT = 'wav'\n",
    "    RATE = '16000'\n",
    "    CHANNEL = 1\n",
    "    CUID = '*******'\n",
    "    SPEECH = base64.b64encode(speech_data).decode('utf-8')\n",
    "\n",
    "    data = {\n",
    "        'format': FORMAT,\n",
    "        'rate': RATE,\n",
    "        'channel': CHANNEL,\n",
    "        'cuid': CUID,\n",
    "        'len': len(speech_data),\n",
    "        'speech': SPEECH,\n",
    "        'token': token,\n",
    "        'dev_pid':dev_pid\n",
    "    }\n",
    "    url = 'https://vop.baidu.com/server_api'\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    # r=requests.post(url,data=json.dumps(data),headers=headers)\n",
    "    print('Identifying...')\n",
    "    r = requests.post(url, json=data, headers=headers)\n",
    "    Result = r.json()\n",
    "    if 'result' in Result:\n",
    "        return Result['result'][0]\n",
    "    else:\n",
    "        return Result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9739f440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "首先，请提供您的姓名、年龄、性别以及手机联系方式\n",
      "请回答\n",
      "正在识别...\n",
      "我叫小明，我是男的，年龄24岁，我的手机号是13813645023。\n",
      "好的，请问您是什么时候开始发现有肺结节的？做过哪些检查？\n",
      "请回答\n",
      "正在识别...\n",
      "我是去年三月体检查了个胸部CT好像是报告说有个肺结节，然后医生就让我每半年。\n",
      "您是否记得结节位于主要在肺的哪个部位？你过去随访过程中结节是否有变化，是否曾就医治疗？\n",
      "请回答\n",
      "正在识别...\n",
      "我的结节好像是位于右上肺，我之前查了几次都没什么变化。\n",
      "您过去有没有患过高血压、糖尿病这一类的慢性疾病，或者对什么药物或物质有过敏反应？是否接受过大型手术？\n",
      "请回答\n",
      "正在识别...\n",
      "我平时身体挺好的，有高血压，在吃药，但是我没有糖尿病，好像也没有什么过敏手术，我也没有做。\n",
      "您平时是否抽烟或者饮酒？具体频率如何？另外，您近期饮食、睡眠如何，是否有不舒服的情况？\n",
      "请回答\n",
      "正在识别...\n",
      "我不喝酒，但是我抽烟，一包能抽2到3天，抽了八年了然后最近我吃饭睡觉都挺好的。\n",
      "好的，感谢您的配合！最后，请问您的爱人、子女以及亲戚朋友中有没有类似情况的健康问题？\n",
      "请回答\n",
      "正在识别...\n",
      "对我姐姐之前也查出来有肺结节，其他人没有都挺健康的。\n",
      "好的，我已经大概搜集好您的情况，您是否有需要补充的？请您告诉我。\n",
      "请回答\n",
      "正在识别...\n",
      "我没啥要补充的了。\n"
     ]
    }
   ],
   "source": [
    "Q_list = [\n",
    "    '首先，请提供您的姓名、年龄、性别以及手机联系方式',\n",
    "    '好的，请问您是什么时候开始发现有肺结节的？做过哪些检查？',\n",
    "    '您是否记得结节位于主要在肺的哪个部位？你过去随访过程中结节是否有变化，是否曾就医治疗？',\n",
    "    '您过去有没有患过高血压、糖尿病这一类的慢性疾病，或者对什么药物或物质有过敏反应？是否接受过大型手术？',\n",
    "    '您平时是否抽烟或者饮酒？具体频率如何？另外，您近期饮食、睡眠如何，是否有不舒服的情况？',\n",
    "    '好的，感谢您的配合！最后，请问您的爱人、子女以及亲戚朋友中有没有类似情况的健康问题？',\n",
    "    '好的，我已经大概搜集好您的情况，您是否有需要补充的？请您告诉我。'\n",
    "]\n",
    "\n",
    "# devpid = input('1536：普通话(简单英文),1537:普通话(有标点),1737:英语,1637:粤语,1837:四川话\\n')\n",
    "devpid = 1537\n",
    "All_Result = []\n",
    "\n",
    "play_sound('您好，我是筛查机器人，负责采集您的一些信息，我将就您肺结节的情况向您咨询一些问题，请您配合我。')\n",
    "play_sound('下面，我们开始。')\n",
    "\n",
    "\n",
    "for item in Q_list:\n",
    "    print(item)\n",
    "    play_sound(item)\n",
    "    print('请回答')\n",
    "    my_record()\n",
    "    TOKEN = getToken(HOST)\n",
    "    speech = get_audio(FILEPATH)\n",
    "    result = speech2text(speech, TOKEN, int(devpid))\n",
    "    print(result)\n",
    "    All_Result.append('%s: %s' % (item, result))\n",
    "play_sound('感谢您的配合，我已将相关信息整理并且发送给您的负责医生，请您进一步至医院就诊。')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:audio]",
   "language": "python",
   "name": "conda-env-audio-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
